{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1300057f-f91e-4461-9452-822fa5889e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import random\n",
    "\n",
    "# how to render in Jupyter: \n",
    "# https://stackoverflow.com/questions/40195740/how-to-run-openai-gym-render-over-a-server\n",
    "# https://www.youtube.com/watch?v=O84KgRt6AJI\n",
    "def show_state(env, step=0, name='', info=''):\n",
    "    plt.figure(3)\n",
    "    plt.clf()\n",
    "    plt.imshow(env.render())\n",
    "    plt.title(\"%s | Step: %d %s\" % (name, step, info))\n",
    "    plt.axis('off')\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    \n",
    "# To transform pixel matrix to a single vector.\n",
    "def getState(inState):\n",
    "    # each row is all 1 color\n",
    "    rgbRows = np.reshape(inState,(len(inState[0])*len(inState), 3)).T\n",
    "\n",
    "    # add each with appropriate shifting\n",
    "    # get RRRRRRRR GGGGGGGG BBBBBBBB\n",
    "    return np.add(np.left_shift(rgbRows[0], 16),\n",
    "        np.add(np.left_shift(rgbRows[1], 8), rgbRows[2]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "122d56dc-7d3d-4eff-827b-51563b12eb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import to do training\n",
    "from tpg.trainer import Trainer\n",
    "# import to run an agent (always needed)\n",
    "from tpg.agent import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1e81276-3164-4d98-925c-686197a19f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(5)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CarRacing-v2', render_mode='rgb_array', continuous=False) # make the environment\n",
    "\n",
    "print(env.action_space) # learn size of action space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66840cdc-0ac4-4b34-8cde-ddeaf465bef1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Trainer.__init__() got an unexpected keyword argument 'teamPopSize'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      4\u001b[0m tStart \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m      6\u001b[0m \u001b[39m# first create an instance of the TpgTrainer\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m# this creates the whole population and everything\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39m# teamPopSize should realistically be at-least 100\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(actions\u001b[39m=\u001b[39m\u001b[39mrange\u001b[39m(\u001b[39m4\u001b[39m), teamPopSize\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m) \n\u001b[1;32m     11\u001b[0m curScores \u001b[39m=\u001b[39m [] \u001b[39m# hold scores in a generation\u001b[39;00m\n\u001b[1;32m     12\u001b[0m summaryScores \u001b[39m=\u001b[39m [] \u001b[39m# record score summaries for each gen (min, max, avg)\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: Trainer.__init__() got an unexpected keyword argument 'teamPopSize'"
     ]
    }
   ],
   "source": [
    "## %matplotlib inline\n",
    "import time # for tracking time\n",
    "\n",
    "tStart = time.time()\n",
    "\n",
    "# first create an instance of the TpgTrainer\n",
    "# this creates the whole population and everything\n",
    "# teamPopSize should realistically be at-least 100\n",
    "trainer = Trainer(actions=range(4), teamPopSize=20) \n",
    "\n",
    "curScores = [] # hold scores in a generation\n",
    "summaryScores = [] # record score summaries for each gen (min, max, avg)\n",
    "\n",
    "# 5 generations isn't much (not even close), but some improvements\n",
    "# should be seen.\n",
    "for gen in range(5): # generation loop\n",
    "    curScores = [] # new list per gen\n",
    "    \n",
    "    agents = trainer.getAgents()\n",
    "    \n",
    "    while True: # loop to go through agents\n",
    "        teamNum = len(agents)\n",
    "        agent = agents.pop()\n",
    "        if agent is None:\n",
    "            break # no more agents, so proceed to next gen\n",
    "        \n",
    "        state = env.reset()[0] # get initial state and prep environment\n",
    "        score = 0\n",
    "        for i in range(500): # run episodes that last 500 frames\n",
    "            show_state(env, i, 'Assault', 'Gen #' + str(gen) + \n",
    "                       ', Team #' + str(teamNum) +\n",
    "                       ', Score: ' + str(score)) # render env\n",
    "            \n",
    "            # must transform to at-least int-32 (for my getState to bitshift correctly)\n",
    "            # print(state)\n",
    "\n",
    "            \n",
    "            act = agent.act(getState(np.array(state, dtype=np.int32)))\n",
    "\n",
    "            print(act)\n",
    "            \n",
    "            # feedback from env\n",
    "            #print(\"act\", act[0])\n",
    "\n",
    "            state, reward, isTerminated, isTruncated, debug = env.step(act[0])\n",
    "            \n",
    "            score += reward # accumulate reward in score\n",
    "            if isTerminated or isTruncated:\n",
    "                break # end early if losing state\n",
    "\n",
    "        agent.reward(score) # must reward agent (if didn't already score)\n",
    "            \n",
    "        curScores.append(score) # store score\n",
    "        \n",
    "        if len(agents) == 0:\n",
    "            break\n",
    "            \n",
    "    # at end of generation, make summary of scores\n",
    "    summaryScores.append((min(curScores), max(curScores),\n",
    "                    sum(curScores)/len(curScores))) # min, max, avg\n",
    "    trainer.evolve()\n",
    "    \n",
    "#clear_output(wait=True)\n",
    "print('Time Taken (Hours): ' + str((time.time() - tStart)/3600))\n",
    "print('Results:\\nMin, Max, Avg')\n",
    "for result in summaryScores:\n",
    "    print(result[0],result[1],result[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c95813-6140-4f17-9f7b-435b4bd36bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378fe7a6-6060-484c-85e2-face0bed8c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytpg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "60b4a3a271b4e61b8ba9f611a3dbc4638058cdf925010470585b0b267a3f4372"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
