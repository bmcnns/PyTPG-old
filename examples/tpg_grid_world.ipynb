{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28da11d1-7d6f-4520-ad49-d2dea3b12929",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtpg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtpg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Agent\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtpg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgridworld\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridWorld\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tpg'"
     ]
    }
   ],
   "source": [
    "from tpg.trainer import Trainer\n",
    "from tpg.agent import Agent\n",
    "from tpg.gridworld import GridWorld\n",
    "from tpg.configurations import DefaultConfiguration\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b354c3a-1397-4a73-9461-9aeabb04eb74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "width = 5\n",
    "height = 5\n",
    "targetCell = (4, 4)\n",
    "walls = [(2, 2), (3, 2), (1, 4), (4, 3)]  # Define wall positions\n",
    "epsilon = 0.25\n",
    "env = GridWorld(width, height, targetCell, walls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c492fa-1dec-4495-a900-e38e0b53a30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "customConfig = DefaultConfiguration()\n",
    "customConfig.teamPopSize = 100\n",
    "\n",
    "numGenerations = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e9adf0-f846-4cb7-8ebf-e8df0826934c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(actions=range(5), config=customConfig)\n",
    "\n",
    "rewardStats = []\n",
    "numStepsStats= []\n",
    "\n",
    "for generation in range(numGenerations):\n",
    "    \n",
    "    rewards = [] # new list every gen\n",
    "    numSteps = [] # new list every gen\n",
    "    \n",
    "    agents = trainer.getAgents()\n",
    "    \n",
    "    while True:\n",
    "        teamNum = len(agents)\n",
    "        agent = agents.pop()\n",
    "        if agent is None:\n",
    "            break # no more agents, proceed to next gen\n",
    "        \n",
    "        env.reset()\n",
    "        score = 0\n",
    "        \n",
    "        \n",
    "        i = 0\n",
    "        \n",
    "        print(f\"Gen #{generation}, Team #{teamNum}, Score: {score}\")\n",
    "            \n",
    "        while not env.isTerminal() and i < 500:\n",
    "            \n",
    "            i += 1\n",
    "            \n",
    "            #env.display()       \n",
    "            \n",
    "            tpg_response = agent.act(env.getState())[1]\n",
    "            \n",
    "            if tpg_response is None:\n",
    "                action = 0\n",
    "            else:\n",
    "                action = np.argmax(tpg_response)\n",
    "            \n",
    "            nextState, reward = env.step(action)\n",
    "            \n",
    "            score += reward\n",
    "        \n",
    "        if i == 500:\n",
    "            print(\"Ran out of turns... giving up\")\n",
    "        \n",
    "        agent.reward(score)\n",
    "        \n",
    "        rewards.append(score)\n",
    "        numSteps.append(i)\n",
    "        \n",
    "        print(f\"Finished after {i} steps with cumulative reward {score}...\")\n",
    "        env.display()\n",
    "        \n",
    "        if len(agents) == 0:\n",
    "            break\n",
    "    \n",
    "    rewardStats.append((min(rewards), max(rewards), sum(rewards)/len(rewards)))\n",
    "    numStepsStats.append((min(numSteps), max(numSteps), sum(numSteps)/len(numSteps)))\n",
    "    trainer.evolve()\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7f9f33-6c41-4a17-bf92-da018202eff1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stepInfo = np.array(numStepsStats)\n",
    "rewardInfo = np.array(rewardStats)\n",
    "\n",
    "stepInfo.shape, rewardInfo.shape\n",
    "\n",
    "min_rewards = rewardInfo[:, 0]\n",
    "max_rewards = rewardInfo[:, 1]\n",
    "avg_rewards = rewardInfo[:, 2]\n",
    "\n",
    "min_steps = stepInfo[:, 0]\n",
    "max_steps = stepInfo[:, 1]\n",
    "avg_steps = stepInfo[:, 2]\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(18, 6))\n",
    "\n",
    "\n",
    "# Plot rewards over time\n",
    "episodes = range(1, len(min_rewards) + 1)\n",
    "axes[0].plot(episodes, min_rewards, label='Min Rewards', color='#1f78b4', alpha=0.8)\n",
    "axes[0].plot(episodes, max_rewards, label='Max Rewards', color='#33a02c', alpha=0.8)\n",
    "axes[0].plot(episodes, avg_rewards, label='Avg Rewards', color='#e31a1c', alpha=0.8)\n",
    "axes[0].set_title('Rewards over Time')\n",
    "axes[0].set_xlabel('Generation')\n",
    "axes[0].set_ylabel('Reward')\n",
    "axes[0].legend(loc='upper right')\n",
    "axes[0].grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Plot steps over time\n",
    "axes[1].plot(episodes, min_steps, label='Min Steps', color='#ff7f00', alpha=0.8)\n",
    "axes[1].plot(episodes, max_steps, label='Max Steps', color='#6a3d9a', alpha=0.8)\n",
    "axes[1].plot(episodes, avg_steps, label='Avg Steps', color='#fdbf6f', alpha=0.8)\n",
    "axes[1].set_title('Steps over Time')\n",
    "axes[1].set_xlabel('Generation')\n",
    "axes[1].set_ylabel('Steps')\n",
    "axes[1].legend(loc='upper right')\n",
    "axes[1].grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\\\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c269dc9b-25ca-4146-bb64-749fa3381cc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine the data into a DataFrame for Seaborn\n",
    "reward_data = np.concatenate([min_rewards, max_rewards, avg_rewards])\n",
    "reward_type = np.repeat(['Min', 'Max', 'Avg'], len(min_rewards))\n",
    "episode_numbers_reward = np.tile(range(1, len(min_rewards) + 1), 3)\n",
    "\n",
    "steps_data = np.concatenate([min_steps, max_steps, avg_steps])\n",
    "steps_type = np.repeat(['Min', 'Max', 'Avg'], len(min_steps))\n",
    "episode_numbers_steps = np.tile(range(1, len(min_steps) + 1), 3)\n",
    "\n",
    "df_reward = pd.DataFrame({'Episode': episode_numbers_reward, 'Reward': reward_data, 'Type': reward_type})\n",
    "df_steps = pd.DataFrame({'Episode': episode_numbers_steps, 'Steps': steps_data, 'Type': steps_type})\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(18, 6))\n",
    "\n",
    "# Create violin plots for rewards\n",
    "sns.violinplot(x='Type', y='Reward', data=df_reward, color='skyblue', inner='quartile', ax=axes[0])\n",
    "axes[0].set_title('Distribution of Rewards')\n",
    "axes[0].set_xlabel('Reward Type')\n",
    "axes[0].set_ylabel('Reward')\n",
    "axes[0].grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Create violin plots for steps\n",
    "sns.violinplot(x='Type', y='Steps', data=df_steps, palette=\"Blues\", inner='quartile', ax=axes[1])\n",
    "axes[1].set_title('Distribution of Steps')\n",
    "axes[1].set_xlabel('Step Type')\n",
    "axes[1].set_ylabel('Steps')\n",
    "axes[1].grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d87cd67-0dee-4cc4-b695-e6a9d286641a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9969afea-6135-4350-9dc6-7ad2c057fc3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytpg",
   "language": "python",
   "name": "pytpg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
